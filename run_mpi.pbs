#!/bin/sh

#PBS -N ParticalSim-Proj                # name of job
#PBS -l nodes=16:ppn=8                  # resources allocated, 1 node 2 processors
#PBS -q coc-ice-multi
#PBS -S /bin/bash
#PBS -V
#PBS -j oe                              # output and error is combined into the same file
#PBS -o mpi-timming.out                 # output file is named gettingStarted.out
#PBS -M cman8@gatech.edu

                                        # computation starts here

# The current pbs is for mpi

cd ~/Parallel-Framework-for-Particle-Dynamics-Simulation

module load gcc cmake openmpi valgrind
module load gcc cmake openmpi valgrind
module load gcc cmake openmpi valgrind
module load gcc cmake openmpi valgrind

# echo "centroid 1m"
# mpirun -np 128  ./build/test/TEST_neo_centroid_mpi 4 4 8 10 10 10 data/data1m.txt
# mpirun -np 64  ./build/test/TEST_neo_centroid_mpi 4 4 4 10 10 20 data/data1m.txt
# mpirun -np 32  ./build/test/TEST_neo_centroid_mpi 4 4 2 10 10 40 data/data1m.txt
# mpirun -np 16  ./build/test/TEST_neo_centroid_mpi 4 2 2 10 20 40 data/data1m.txt
# mpirun -np 8 ./build/test/TEST_neo_centroid_mpi 2 2 2 20 20 40 data/data1m.txt
# mpirun -np 4 ./build/test/TEST_neo_centroid_mpi 2 2 1 20 20 80 data/data1m.txt
# mpirun -np 2 ./build/test/TEST_neo_centroid_mpi 1 2 1 40 20 80 data/data1m.txt

echo "centroid 10k"
mpirun -np 128  ./build/test/TEST_neo_centroid_mpi 4 4 8 1 1 1 data/data10k.txt
mpirun -np 64  ./build/test/TEST_neo_centroid_mpi 4 4 4 1 1 1 data/data10k.txt
mpirun -np 32  ./build/test/TEST_neo_centroid_mpi 4 4 2 1 1 1 data/data10k.txt
mpirun -np 16  ./build/test/TEST_neo_centroid_mpi 4 2 2 1 1 1 data/data10k.txt
mpirun -np 8 ./build/test/TEST_neo_centroid_mpi 2 2 2 1 1 1 data/data10k.txt
mpirun -np 4 ./build/test/TEST_neo_centroid_mpi 2 2 1 1 1 1 data/data10k.txt
mpirun -np 2 ./build/test/TEST_neo_centroid_mpi 1 2 1 1 1 1 data/data10k.txt

# echo "cutoff 1m"
# mpirun -np 128  ./build/test/TEST_neo_cutoff_mpi 4 4 8 10 10 10 data/data1m.txt
# mpirun -np 64  ./build/test/TEST_neo_cutoff_mpi 4 4 4 10 10 20 data/data1m.txt
# mpirun -np 32  ./build/test/TEST_neo_cutoff_mpi 4 4 2 10 10 40 data/data1m.txt
# mpirun -np 16  ./build/test/TEST_neo_cutoff_mpi 4 2 2 10 20 40 data/data1m.txt
# mpirun -np 8 ./build/test/TEST_neo_cutoff_mpi 2 2 2 20 20 40 data/data1m.txt
# mpirun -np 4 ./build/test/TEST_neo_cutoff_mpi 2 2 1 20 20 80 data/data1m.txt
# mpirun -np 2 ./build/test/TEST_neo_cutoff_mpi 1 2 1 40 20 80 data/data1m.txt

echo "cutoff 10k"
mpirun -np 128  ./build/test/TEST_neo_cutoff_mpi 4 4 8 1 1 1 data/data10k.txt
mpirun -np 64  ./build/test/TEST_neo_cutoff_mpi 4 4 4 1 1 1 data/data10k.txt
mpirun -np 32  ./build/test/TEST_neo_cutoff_mpi 4 4 2 1 1 1 data/data10k.txt
mpirun -np 16  ./build/test/TEST_neo_cutoff_mpi 4 2 2 1 1 1 data/data10k.txt
mpirun -np 8 ./build/test/TEST_neo_cutoff_mpi 2 2 2 1 1 1 data/data10k.txt
mpirun -np 4 ./build/test/TEST_neo_cutoff_mpi 2 2 1 1 1 1 data/data10k.txt
mpirun -np 2 ./build/test/TEST_neo_cutoff_mpi 1 2 1 1 1 1 data/data10k.txt

# mpirun -np 16 --map-by node:pe=8 ./build/test/TEST_neo_dense_mpi 4 4 data/data10k.txt
# mpirun -np 12 --map-by node:pe=8 ./build/test/TEST_neo_dense_mpi 3 4 data/data10k.txt
# mpirun -np 8 --map-by node:pe=8 ./build/test/TEST_neo_dense_mpi 2 4 data/data10k.txt
# mpirun -np 6 --map-by node:pe=8 ./build/test/TEST_neo_dense_mpi 2 3 data/data10k.txt
# mpirun -np 4 --map-by node:pe=8 ./build/test/TEST_neo_dense_mpi 2 2 data/data10k.txt
# mpirun -np 2 --map-by node:pe=8 ./build/test/TEST_neo_dense_mpi 1 2 data/data10k.txt
